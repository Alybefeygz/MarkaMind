"""
One-time Migration Script
Chunk all existing PDFs in knowledge_base_entries
"""
import asyncio
from app.config.settings import settings
from app.services.chunking_service import chunking_service
from supabase import create_client, Client


async def migrate_existing_pdfs():
    """Chunk all existing PDFs that don't have chunks yet"""

    print("=" * 60)
    print("ğŸ“š CHUNKING MIGRATION SCRIPT")
    print("=" * 60)
    print()

    # Initialize Supabase client (using service role key for admin access)
    supabase: Client = create_client(settings.SUPABASE_URL, settings.SUPABASE_API_KEY)

    # 1. Get all knowledge base entries with content
    print("ğŸ” Mevcut PDF'leri buluyorum...")
    result = supabase.table("knowledge_base_entries").select(
        "id, chatbot_id, source_name, content, status"
    ).not_.is_("content", "null").execute()

    if not result.data:
        print("âŒ HiÃ§ PDF bulunamadÄ±!")
        return

    total_pdfs = len(result.data)
    print(f"âœ… {total_pdfs} adet PDF bulundu\n")

    # Statistics
    already_chunked = 0
    successfully_chunked = 0
    failed = 0
    total_chunks_created = 0

    # 2. Process each PDF
    for idx, entry in enumerate(result.data, 1):
        source_id = entry["id"]
        source_name = entry.get("source_name", "unknown.pdf")
        content = entry.get("content", "")

        print(f"[{idx}/{total_pdfs}] ğŸ“„ {source_name}")

        # Check if already chunked
        existing_chunks = supabase.table("knowledge_chunks").select(
            "id", count="exact"
        ).eq("knowledge_entry_id", source_id).execute()

        if existing_chunks.count and existing_chunks.count > 0:
            print(f"  â­ï¸  Zaten chunk'lanmÄ±ÅŸ ({existing_chunks.count} chunk)")
            already_chunked += 1
            continue

        # Check content
        if not content or len(content.strip()) < 100:
            print(f"  âš ï¸  Ä°Ã§erik Ã§ok kÄ±sa veya boÅŸ, atlanÄ±yor")
            failed += 1
            continue

        try:
            # Chunk the text
            chunks = chunking_service.chunk_text(
                text=content,
                source_name=source_name
            )

            if not chunks:
                print(f"  âŒ Chunk oluÅŸturulamadÄ±")
                failed += 1
                continue

            # Prepare chunk records
            chunk_records = []
            for chunk in chunks:
                chunk_records.append({
                    "knowledge_entry_id": source_id,
                    "chatbot_id": entry["chatbot_id"],
                    "chunk_index": chunk["chunk_index"],
                    "content": chunk["content"],
                    "token_count": chunk["token_count"],
                    "metadata": chunk["metadata"]
                })

            # Insert chunks
            insert_result = supabase.table("knowledge_chunks").insert(chunk_records).execute()

            if insert_result.data:
                chunks_count = len(insert_result.data)
                total_chunks_created += chunks_count
                print(f"  âœ… {chunks_count} chunk oluÅŸturuldu")
                successfully_chunked += 1
            else:
                print(f"  âŒ Database insert hatasÄ±")
                failed += 1

        except Exception as e:
            print(f"  âŒ Hata: {str(e)}")
            failed += 1

        print()

    # 3. Print summary
    print("=" * 60)
    print("ğŸ“Š Ã–ZET")
    print("=" * 60)
    print(f"Toplam PDF:           {total_pdfs}")
    print(f"Zaten chunk'lanmÄ±ÅŸ:   {already_chunked}")
    print(f"BaÅŸarÄ±yla chunk'landÄ±: {successfully_chunked}")
    print(f"BaÅŸarÄ±sÄ±z:            {failed}")
    print(f"Toplam chunk oluÅŸtu:  {total_chunks_created}")
    print("=" * 60)
    print()

    if successfully_chunked > 0:
        print(f"âœ… Migration baÅŸarÄ±lÄ±! {successfully_chunked} PDF chunk'landÄ±.")
    else:
        print("âš ï¸ HiÃ§bir yeni PDF chunk'lanmadÄ±.")


if __name__ == "__main__":
    asyncio.run(migrate_existing_pdfs())
